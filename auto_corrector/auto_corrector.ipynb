{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto corrector and bayes theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Origin**\n",
    "\n",
    "Couple months ago, I had a project which needs to filter keywords on UGC data. But the challenge is the UGC data has some level of mis-spelling and I need some method to cleanup the mis-spellings.\n",
    "I was trying with regex functions, but it was not that robust and needed a lot of customization.\n",
    "Then I turned to something like auto corrector.\n",
    "I found this amazing post by [Peter Norvig](https://norvig.com/spell-correct.html).\n",
    "\n",
    "He not only engineered the applicaton very efficiently which only contains like 20 lines of code, but also provided all the mathmatic concepts like Bayes Theorem to to support the modeling process. \n",
    "\n",
    "**Definition and Notation**\n",
    "\n",
    "We can define **w** as the original word given, and **c** as the the word after correction. And we can also define all the possible corrections as set **C**, so we have \n",
    "$c\\in C$.\n",
    "\n",
    "\n",
    "Then we can describe the problem as: given the original word **w**, what would be the best correction **c** out of set **C**. \n",
    "\n",
    "If we use probability to model the question, then $p_{(w)}$ would be the probability of original word **w**, $p_{(c)}$ would be the probability of corrected word **c**, and conditional probability $p_{(c|w)}$ would be the probability of corrected word **c** given the condition of the original word **w**.\n",
    "\n",
    "Then the question becomes, given the original word **w**, which **c** should we choose in order to maximize value of $p_{(c|w)}$.\n",
    "\n",
    "Math notaion as: $\\underset{c\\in C}{\\operatorname{argmax}}p_{(c|w)}$\n",
    "\n",
    "\n",
    "But the question remains: how to solve $p_{(c|w)}$?\n",
    "\n",
    "**Bayes Theorem**\n",
    "\n",
    "The general form of Bayes Theorem can be represented like this:\n",
    "$$p_{(A|B)}=\\frac{p_{(B|A)}p_{(A)}}{p_{(B)}}$$\n",
    "\n",
    "This important theorem tells us: if we can't sovle $p_{(c|w)}$ directly, we can choose to solve right side of the equation.\n",
    "\n",
    "In here, our target is to solve $p_{(c|w)}$, and by Bayes Theorem we have $p_{(c|w)}=\\frac{p_{(w|c)}p_{(c)}}{p_{(w)}}$, thus target function becomes\n",
    "\n",
    " $$\\underset{c\\in C}{\\operatorname{argmax}}\\frac{p_{(w|c)}p_{(c)}}{p_{(w)}}$$\n",
    "\n",
    "we can assume that $p_{(w)}$ is indifferent for each correction of **c**, thus we can get rid of it without changing value of $\\underset{c\\in C}{\\operatorname{argmax}}$ function.\n",
    "\n",
    "Then we have target function as  $$\\underset{c\\in C}{\\operatorname{argmax}}p_{(w|c)}p_{(c)}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
